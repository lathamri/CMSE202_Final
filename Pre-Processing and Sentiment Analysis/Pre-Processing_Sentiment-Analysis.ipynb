{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Includes plus re for string handling and nltk for simple language processing\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_process():\n",
    "    \"\"\"\n",
    "    This class is designed to take a filename linking to a text file and return a cleaned list for processing.\n",
    "    \"\"\"\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Take in a filename as a string to work on.\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Get our data from some txt file. This will be split by word to be.\n",
    "        \"\"\"\n",
    "        # Load our txt file and split it by word\n",
    "        self.data = open(self.filename).read().split()\n",
    "        return self.data\n",
    "    \n",
    "    def seperate_speeches(self):\n",
    "        \"\"\"\n",
    "        This splits our speeches into seperate lists depending on who is speaking.\n",
    "        If new speeches are included you may input the names of the moderaters and speakers.\n",
    "        It returns a list of three lists with all speaking points for each speaker contatenated.\n",
    "        \"\"\"\n",
    "        debate = self.data\n",
    "        mod_list = []\n",
    "        can1_list = []\n",
    "        can2_list = []\n",
    "\n",
    "        i_new = -1\n",
    "        i_old = -1\n",
    "        while i_new >= -len(debate):\n",
    "            if (debate[i_new] == 'LEHRER:' or debate[i_new] == 'CROWLEY:' or debate[i_new] == 'SCHIEFFER:'\n",
    "                    or debate[i_new] == 'HOLT:' or debate[i_new] == 'RADDATZ:'or debate[i_new] == 'WALLACE:'):\n",
    "                mod_list += debate[i_new:]\n",
    "                del debate[i_new:i_old]\n",
    "                i_old = i_new\n",
    "\n",
    "            elif debate[i_new] == 'OBAMA:' or debate[i_new] == 'CLINTON:':\n",
    "                can1_list += debate[i_new:]\n",
    "                del debate[i_new:i_old]\n",
    "                i_old = i_new\n",
    "\n",
    "            elif debate[i_new] == 'ROMNEY:' or debate[i_new] == 'TRUMP:':\n",
    "                can2_list += debate[i_new:]\n",
    "                del debate[i_new:i_old]\n",
    "                i_old = i_new\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "            i_new -= 1\n",
    "        \n",
    "        speeches = (can1_list, can2_list)\n",
    "        \n",
    "        can_aslists = []\n",
    "        for j in range(2):\n",
    "            can_aslists.append(' '.join(speeches[j]))\n",
    "        return can_aslists\n",
    "    \n",
    "    def clean(self, data):\n",
    "        \"\"\"\n",
    "        Takes in our data and strips all unnecessary characters and names for efficiency.\n",
    "        This step is not required for basic sentiment analysis in general, but is for more\n",
    "        complex analysis.\n",
    "        \"\"\"\n",
    "        # Characters to remove\n",
    "        remove = re.compile(r\"[\\'\\\"\\\\\\!\\,\\/\\;\\{\\}\\[\\.\\]]\")\n",
    "        remove_names = re.compile(r'(ROMNEY:) (OBAMA:) (LEHRER:) (CLINTON:) (SCHIEFFER:) (CRAWLEY:) (TRUMP:)')\n",
    "        # List to store clean speeches\n",
    "        removed_names = []\n",
    "        clean_data = []\n",
    "        # Loop over each speech and remove all regex excluded characters defined above\n",
    "        for speech in data:\n",
    "            remove_char = remove.sub(\"\", speech)\n",
    "            removed_names.append(remove_char)\n",
    "        for speech in removed_names:\n",
    "            clean_speech = remove_names.sub(\"\", speech)\n",
    "            clean_data.append(clean_speech)\n",
    "\n",
    "        return clean_data\n",
    "    \n",
    "    def remove_stop_words(self, clean_speeches):\n",
    "        \"\"\"\n",
    "        Use nltk stopwords to remove a subset of words from each space.\n",
    "        The removed words take away very little context and so don't affect analysis, but \n",
    "        is much quicker to sort through for analysis.\n",
    "        \"\"\"\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "        removed_words_speeches = []\n",
    "        for speech in clean_speeches:\n",
    "            removed_words_speeches.append(' '.join([word for word in speech.split() if word not in stop_words]))\n",
    "        return removed_words_speeches\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_analysis():\n",
    "    \"\"\"\n",
    "    This class loads in our positive and negative words for our sentiment analysis and counts\n",
    "    the good and bad sentiment words for each speech given.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Take in our data and store it.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "    \n",
    "    def read_good_bad(self, pos, neg):\n",
    "        \"\"\"\n",
    "        Create a list containing the words with positive and negative sentiment.\n",
    "        \"\"\"\n",
    "        self.pos = np.loadtxt(pos, dtype = str,encoding=\"ISO-8859-1\")\n",
    "        self.neg = np.loadtxt(neg, dtype=str ,encoding=\"ISO-8859-1\")\n",
    "        return [list(self.pos), list(self.neg)]\n",
    "\n",
    "    def sentiment_count(self, speech):\n",
    "        \"\"\"\n",
    "        Count the good and bad sentiment words for each speech and return them as a tuple.\n",
    "        \"\"\"\n",
    "        good_count = [x for x in speech if x in good_bad[0]]\n",
    "        bad_count = [x for x in speech if x in good_bad[1]]\n",
    "        return (good_count, bad_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our data locations\n",
    "\n",
    "Speech_list = ['/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/CMSE_Final_files/Obama_Romeny_1.txt',\n",
    "                '/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/CMSE_Final_files/Obama_Romeny_2.txt',\n",
    "                '/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/CMSE_Final_files/Obama_Romeny_3.txt',\n",
    "                '/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/CMSE_Final_files/Clinton_Trump_1.txt',\n",
    "                '/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/CMSE_Final_files/Clinton_Trump_2.txt',\n",
    "                '/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/CMSE_Final_files/Clinton_Trump_3.txt']\n",
    "\n",
    "good_list = '/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/CMSE_Final_files/positive-words.txt'\n",
    "bad_list = '/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/CMSE_Final_files/negative-words.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize temporary values for storing, indexing, and date placement.\n",
    "output = []\n",
    "i = 0\n",
    "j = 0\n",
    "Debate_Date = ['10/3/2012', '10/16/2012', '10/22/2012', '9/26/2016', '10/9/2016', '10/19/2016']\n",
    "\n",
    "# Loop over all speeches in the list above\n",
    "for val in Speech_list:\n",
    "    \n",
    "    # grab the speech\n",
    "    data = pre_process(val)\n",
    "\n",
    "    # extract the speeches data\n",
    "    y = data.get_data()\n",
    "\n",
    "    # seperate the speeches by speaker\n",
    "    r = data.seperate_speeches()\n",
    "\n",
    "    # clean each speech\n",
    "    x = data.clean(r)\n",
    "\n",
    "    # remove the stop words\n",
    "    z = data.remove_stop_words(x)\n",
    "    \n",
    "    # initialize our analysis on the cleaned speech\n",
    "    SA = sentiment_analysis(z)\n",
    "    \n",
    "    # grab our positive and negative sentiment list\n",
    "    good_bad = SA.read_good_bad(good_list, bad_list)\n",
    "    \n",
    "    # loop over each speaker in the speech\n",
    "    for q in range(len(z)):\n",
    "        # finds out who is speaking based on indexing\n",
    "        if i==0 or i==1 or i==2:\n",
    "            # Democrates come first \n",
    "            if q==0:\n",
    "                Candidate_Name = 'Obama'\n",
    "                Affiliation = 'D'\n",
    "                Election_Year = 2012\n",
    "            else:\n",
    "                Candidate_Name = 'Romney'\n",
    "                Affiliation = 'R'\n",
    "                Election_Year = 2012\n",
    "        if i==3 or i==4 or i==5:\n",
    "            if q==0:\n",
    "                Candidate_Name = 'Clinton'\n",
    "                Affiliation = 'D'\n",
    "                Election_Year = 2016\n",
    "            else:\n",
    "                Candidate_Name = 'Trump'\n",
    "                Affiliation = 'R'\n",
    "                Election_Year = 2016\n",
    "        # split our speeches by word to perform analysis\n",
    "        y = SA.sentiment_count(z[q].split())\n",
    "        good = len(y[0])\n",
    "        bad = len(y[1])\n",
    "        \n",
    "        # return the prefered data.\n",
    "        output.append([Election_Year, Debate_Date[j], Candidate_Name, Affiliation, good, bad, good+bad])\n",
    "    i += 1\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create it as a pandas Data Frame\n",
    "sentiment_12_16 = pd.DataFrame(output, columns=['Election_Year', 'Debate_Date', 'Candidate_Name', 'Affiliation', 'Positive_Words', 'Negative_Words', 'Total_Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export it as a csv\n",
    "sentiment_12_16.to_csv('SentimentData_12-16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Election_Year</th>\n",
       "      <th>Debate_Date</th>\n",
       "      <th>Candidate_Name</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Positive_Words</th>\n",
       "      <th>Negative_Words</th>\n",
       "      <th>Total_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>10/3/2012</td>\n",
       "      <td>Obama</td>\n",
       "      <td>D</td>\n",
       "      <td>3824</td>\n",
       "      <td>1438</td>\n",
       "      <td>5262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>10/3/2012</td>\n",
       "      <td>Romney</td>\n",
       "      <td>R</td>\n",
       "      <td>4307</td>\n",
       "      <td>1641</td>\n",
       "      <td>5948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>10/16/2012</td>\n",
       "      <td>Obama</td>\n",
       "      <td>D</td>\n",
       "      <td>3240</td>\n",
       "      <td>1748</td>\n",
       "      <td>4988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>10/16/2012</td>\n",
       "      <td>Romney</td>\n",
       "      <td>R</td>\n",
       "      <td>4628</td>\n",
       "      <td>2448</td>\n",
       "      <td>7076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>10/22/2012</td>\n",
       "      <td>Obama</td>\n",
       "      <td>D</td>\n",
       "      <td>4569</td>\n",
       "      <td>2393</td>\n",
       "      <td>6962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>10/22/2012</td>\n",
       "      <td>Romney</td>\n",
       "      <td>R</td>\n",
       "      <td>4368</td>\n",
       "      <td>2255</td>\n",
       "      <td>6623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>9/26/2016</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>D</td>\n",
       "      <td>3704</td>\n",
       "      <td>3388</td>\n",
       "      <td>7092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>9/26/2016</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>4637</td>\n",
       "      <td>4225</td>\n",
       "      <td>8862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>10/9/2016</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>D</td>\n",
       "      <td>2646</td>\n",
       "      <td>2416</td>\n",
       "      <td>5062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>10/9/2016</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>3571</td>\n",
       "      <td>3353</td>\n",
       "      <td>6924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>10/19/2016</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>D</td>\n",
       "      <td>5446</td>\n",
       "      <td>4316</td>\n",
       "      <td>9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>10/19/2016</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>5720</td>\n",
       "      <td>4439</td>\n",
       "      <td>10159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Election_Year Debate_Date Candidate_Name Affiliation  Positive_Words  \\\n",
       "0            2012   10/3/2012          Obama           D            3824   \n",
       "1            2012   10/3/2012         Romney           R            4307   \n",
       "2            2012  10/16/2012          Obama           D            3240   \n",
       "3            2012  10/16/2012         Romney           R            4628   \n",
       "4            2012  10/22/2012          Obama           D            4569   \n",
       "5            2012  10/22/2012         Romney           R            4368   \n",
       "6            2016   9/26/2016        Clinton           D            3704   \n",
       "7            2016   9/26/2016          Trump           R            4637   \n",
       "8            2016   10/9/2016        Clinton           D            2646   \n",
       "9            2016   10/9/2016          Trump           R            3571   \n",
       "10           2016  10/19/2016        Clinton           D            5446   \n",
       "11           2016  10/19/2016          Trump           R            5720   \n",
       "\n",
       "    Negative_Words  Total_Sentiment  \n",
       "0             1438             5262  \n",
       "1             1641             5948  \n",
       "2             1748             4988  \n",
       "3             2448             7076  \n",
       "4             2393             6962  \n",
       "5             2255             6623  \n",
       "6             3388             7092  \n",
       "7             4225             8862  \n",
       "8             2416             5062  \n",
       "9             3353             6924  \n",
       "10            4316             9762  \n",
       "11            4439            10159  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_12_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
