{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Includes\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_process():\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"Get our data from some csv file. The file should be a csv.\n",
    "        Each cell should be a string and each string should be one entire speech.\n",
    "        Must be run prior to clean().\"\"\"\n",
    "        # Load our csv as strings\n",
    "        self.data = pd.read_csv(self.filename)\n",
    "        return list(self.data)\n",
    "    \n",
    "    def clean(self):\n",
    "        \"\"\"Takes in our data and strips all unnecessary characters.\"\"\"\n",
    "        # Characters to remove\n",
    "        remove = re.compile(r\"[\\'\\\"\\\\\\!\\,\\/\\;\\{\\}\\[\\.\\]]\")\n",
    "        remove_names = re.compile(r'(TRUMP:) (CLINTON:) (HOLT:)')\n",
    "        # List to store clean speeches\n",
    "        removed_names = []\n",
    "        clean_data = []\n",
    "        # Loop over each speech and remove all regex excluded characters defined above in remove\n",
    "        for speech in self.data:\n",
    "            remove_char = remove.sub(\"\", speech)\n",
    "            removed_names.append(remove_char)\n",
    "        for speech in removed_names:\n",
    "            clean_speech = remove_names.sub(\"\", speech)\n",
    "            clean_data.append(clean_speech)\n",
    "\n",
    "        return clean_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_analysis():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def read_good_bad(self, pos, neg):\n",
    "        self.pos = np.loadtxt(pos, dtype = str,encoding=\"ISO-8859-1\")\n",
    "        self.neg = np.loadtxt(neg, dtype=str ,encoding=\"ISO-8859-1\")\n",
    "        return [list(self.pos), list(self.neg)]\n",
    "    \n",
    "    def remove_stop_words(self):\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "        removed_words_speeches = []\n",
    "        for speech in self.data:\n",
    "            removed_words = []\n",
    "            removed_words.append(' '.join([word for word in speech.split() if word not in stop_words]))\n",
    "            removed_words_speeches.append(removed_words)\n",
    "        return removed_words_speeches\n",
    "    \n",
    "    def sentiment_count(self):\n",
    "        good_count = 0\n",
    "        bad_count = 0\n",
    "        for speech in removed_word_speeches:\n",
    "            for word in speech.lower():\n",
    "                # looking for way to efficiently check sorted lists, considering binary sorting algo\n",
    "                pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['String 1, in at the Always Trying Economics TRUMP . ! [ ]', 'String 2, TRUMP: CLINTON: HOLT:{ }', 'String 3, / \\\\']\n",
      "String 1 in at the Always Trying Economics TRUMP    \n",
      "String 2  \n",
      "String 3  \n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "data = pre_process('CMSE202_TestFile - Sheet1.csv')\n",
    "\n",
    "y = data.get_data()\n",
    "print(y)\n",
    "\n",
    "x = data.clean()\n",
    "for obj in x:\n",
    "    print(obj)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = '/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/Text Pre-Processing/opinion-lexicon-English/positive-words.txt'\n",
    "bad_list = '/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/Text Pre-Processing/opinion-lexicon-English/negative-words.txt'\n",
    "\n",
    "SA = sentiment_analysis(x)\n",
    "good_bad = SA.read_good_bad(good_list, bad_list)\n",
    "clean_speeches = SA.remove_stop_words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['String 1 Always Trying Economics TRUMP'], ['String 2'], ['String 3']]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
