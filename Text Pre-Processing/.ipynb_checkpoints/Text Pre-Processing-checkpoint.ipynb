{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Includes\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_process():\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"Get our data from some csv file. The file should be a csv.\n",
    "        Each cell should be a string and each string should be one entire speech.\n",
    "        Must be run prior to clean().\"\"\"\n",
    "        # Load our csv as strings\n",
    "        self.data = pd.read_csv(self.filename)\n",
    "        return list(self.data)\n",
    "    \n",
    "    def clean(self):\n",
    "        \"\"\"Takes in our data and strips all unnecessary characters.\"\"\"\n",
    "        # Characters to remove\n",
    "        remove = re.compile(r\"[\\'\\\"\\\\\\!\\,\\/\\;\\{\\}\\[\\.\\]]\")\n",
    "        remove_names = re.compile(r'(MCCAIN:) (OBAMA:) (LEHRER:)')\n",
    "        # List to store clean speeches\n",
    "        removed_names = []\n",
    "        clean_data = []\n",
    "        # Loop over each speech and remove all regex excluded characters defined above in remove\n",
    "        for speech in self.data:\n",
    "            remove_char = remove.sub(\"\", speech)\n",
    "            removed_names.append(remove_char)\n",
    "        for speech in removed_names:\n",
    "            clean_speech = remove_names.sub(\"\", speech)\n",
    "            clean_data.append(clean_speech)\n",
    "\n",
    "        return clean_data\n",
    "    \n",
    "    def remove_stop_words(self, clean_speeches):\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "        removed_words_speeches = []\n",
    "        for speech in clean_speeches:\n",
    "            removed_words_speeches.append(' '.join([word for word in speech.split() if word not in stop_words]))\n",
    "        return removed_words_speeches\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_analysis():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def read_good_bad(self, pos, neg):\n",
    "        self.pos = np.loadtxt(pos, dtype = str,encoding=\"ISO-8859-1\")\n",
    "        self.neg = np.loadtxt(neg, dtype=str ,encoding=\"ISO-8859-1\")\n",
    "        return [list(self.pos), list(self.neg)]\n",
    "\n",
    "    def sentiment_count(self, speech):\n",
    "        good_count = [x for x in speech if x in good_bad[0]]\n",
    "        bad_count = [x for x in speech if x in good_bad[1]]\n",
    "        return (good_count, bad_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "data = pre_process('/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/Debate_Scrape/Obama_McCain_1_sep.csv')\n",
    "\n",
    "y = data.get_data()\n",
    "\n",
    "x = data.clean()\n",
    "\n",
    "z = data.remove_stop_words(x)\n",
    "\n",
    "print(len(z[2].split()[0:50000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = '/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/Text Pre-Processing/opinion-lexicon-English/positive-words.txt'\n",
    "bad_list = '/Users/rileylatham/Downloads/CMSE202/CMSE202_Final/Text Pre-Processing/opinion-lexicon-English/negative-words.txt'\n",
    "\n",
    "SA = sentiment_analysis(z)\n",
    "good_bad = SA.read_good_bad(good_list, bad_list)\n",
    "y = SA.sentiment_count(z[2].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3048\n"
     ]
    }
   ],
   "source": [
    "print(len(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
